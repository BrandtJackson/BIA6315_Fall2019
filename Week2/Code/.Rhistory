set.seed(123)
data <- rnorm(100)
head(data)
tail(data)
hist(data)
qqnorm(data)
qqline(data, col = 2)
mean.manual <- sum(data)/100
print(mean.manual)
mean.automatic <- mean(data)
print(mean.automatic)
#Second moment: Variance (Spread)
variance.manual <- sum((data-mean.manual)^2)/(99)
print(variance.manual)
variance.automatic <- var(data)
print(variance.automatic)
sigma <- sqrt(variance.manual)
print(sigma)
sd(data) #automatic approach
#Third moment: Skewness (Symmetry)
skewness.manual <- (sum((data-mean.manual)^3))/(99*sigma^3)
print(skewness.manual)
library(moments)
skewness.automatic <- skewness(data)
print(skewness.automatic) #pretty close
kurtosis.manual <- (sum((data-mean.manual)^4))/(99*sigma^4)
print(kurtosis.manual)
kurtosis.automatic <- kurtosis(data)
print(kurtosis.automatic) #pretty close again
library(tseries)
library(zoo)
#import dataset into a dataframe
cisco <- read.table('C:/Users/Xuan Pham/Dropbox/Fall_2019/BIA6315/code/Week 2/Data/cisco_00-10.csv', header=T, sep=',')
# create time series for cisco prices
ciscots <- zoo(cisco$Price, as.Date(as.character(cisco$Date), format = "%m/%d/%y"))
plot(ciscots)
hist(ciscots)
mean(ciscots)
plot(ciscots)
hist(ciscots)
mean(ciscots)
log.ciscots <- log(ciscots)
head(log.ciscots)
hist(log.ciscots)
plot(log.ciscots)
plot(ciscots)
decompose(log.ciscots)
?decompose
decompose(coredata(log.ciscots))
log.cisco <- as.ts(log.ciscots)
decompose(log.cisco)
lagged.ciscots <- lag(log.ciscots, k=-1)
price.diff <- (log.ciscots - lagged.ciscots)
head(price.diff)
rts = diff(log.ciscots, lag=1) #default is lag = 1
head(rts)
hist(rts) #any difference?
plot(rts)
rt <- coredata(rts) #keeping just the price data. No time index.
library(fBasics)
# COMPUTE SUMMARY STATISTICS
basicStats(rt)
library(moments)
skewness(rt)
kurtosis(rt)
# CREATE HISTOGRAM
# OPTIONAL creates 2 by 2 display for 4 plots
# par(mfcol=c(2,2))
hist(rt, xlab="Cisco log returns", prob=TRUE, main="Histogram")
# add approximating normal density curve
xfit<-seq(min(rt),max(rt),length=60)
yfit<-dnorm(xfit,mean=mean(rt),sd=sd(rt))
lines(xfit, yfit, col="blue", lwd=2)
normalTest(rt,method=c("jb"))
acf(rt, plot=F)
#plot acf values on graph (correlogram)
acf(rt, plot=T)
# to Lag 3
Box.test(rt,lag=3,type='Ljung')
library(quantmod)
getSymbols("DJIA", src = "FRED",auto.assign=TRUE)  #-- takes ticker names and pulls data from FRED
library(quantmod)
getSymbols("DJIA", src = "FRED",auto.assign=TRUE)  #-- takes ticker names and pulls data from FRED
#default is 10 years back
class(DJIA)
head(DJIA)
tail(DJIA)
head(DJIA, 100) #Can you spot the NAs?
library(zoo)
temp <- zoo(na.omit(DJIA))
mydj <- zoo(temp[1:length(temp)])
class(mydj)
head(mydj)
tail(mydj)
plot(mydj, main = "Dow Jones Industrial average \n 27 Aug 2009 - 26 Aug 2019", ylab = "Index")
tail(mydj, 250) #find out the start date for series
mydj.short <- window(mydj, start = as.Date("2018-08-24")) #note the indexes - you can change this if you want
plot(mydj.short, main = "Dow Jones Industrial average \n 250 trading days ending 26 Aug 2019",  ylab = "Index")
mydj.short.coredata <- coredata(mydj.short)
hist(mydj.short.coredata)
mean(mydj.short.coredata)
skewness(mydj.short.coredata)
kurtosis(mydj.short.coredata)
kurtosis(mydj.short.coredata)
normalTest(mydj.short.coredata, method="jb")
mydj.short.log <- log(mydj.short.coredata)
hist(mydj.short.log)
diff_mydj <- diff(mydj.short)
plot(diff_mydj, main = "Change in daily Dow Jones Industrial average \n 250 trading days ending 26 Aug 2019", ylab = "Change in index")
abline(a=0,b=0, col = "red")
diff_mydj <- diff(mydj.short.log)
plot(diff_mydj, main = "Change in daily Dow Jones Industrial average \n 250 trading days ending 26 Aug 2019", ylab = "Change in index")
abline(a=0,b=0, col = "red")
diff_mydj <- diff(mydj.short)
plot(diff_mydj, main = "Change in daily Dow Jones Industrial average \n 250 trading days ending 26 Aug 2019", ylab = "Change in index")
abline(a=0,b=0, col = "red")
acf(coredata(diff_mydj), plot=T) #note that the acf function only work with core data (i.e. no time index).
Box.test(diff_mydj, lag=10, fitdf=0, type="Lj")
library(fpp2) #this is the package for the textbook
#hsales data set is in fpp2 package
library(forecast)
seasonplot(window(hsales,start = 1985), year.labels = TRUE, col = 1:10, main = "Seasonal plots of home sales") #narrower window
plot(decompose(hsales)) #data set is from package
plot(stl(hsales,s.window="periodic"))
hsales.decomp <- decompose(hsales)
plot(hsales.decomp$seasonal, main = "Home sales seasonal pattern")
plot(hsales.decomp$trend, main = "Home sales trend pattern")
```{r}
urates <- c("UNRATENSA", "UNRATE")
getSymbols(urates, src="FRED")  #-- takes ticker names and pulls data from FRED
start(UNRATENSA)
end(UNRATENSA)
class(UNRATENSA)
#suggestions for improving the 2 step process of creating a time series element with the correct dimensions are welcome
#first series
temp <- ts(UNRATENSA)
dim(temp)
ur.nsa <- ts(temp[1:823], start = c(1948,1), end = c(1948, length(UNRATENSA)),frequency = 12)
dim(ur.nsa)
#second series
temp <- ts(UNRATE)
ur<- ts(temp, start = c(1948,1), end = c(1948, length(UNRATE)), frequency = 12)
plot(ur, main = "Full unemployment rate from FRED")
ur.nsa.short <- window(ur.nsa, start = 2006)
ur.short <- window(ur, start = 2006)
plot(ur.nsa.short, ylab = "Percent", main = "Civilian unemployment rate")
lines(ur.short, col = "blue")
legend("topleft", legend=c("Unadjusted","Adjusted"), col=c("black","blue"), lty = 1)
plot(decompose(ur.nsa.short))
plot(stl(ur.nsa.short, s.window = "periodic"))
ur.nsa.decomp <- decompose(ur.nsa.short)
ur.nsa.stl <- stl(ur.nsa.short, s.window = "periodic")
plot(ur.nsa.decomp$seasonal, main = "Unemployment seasonal pattern")
lines(ur.nsa.stl$time.series[,1], col = "blue")
#decomposition first, then adjustment
fit <- stl(ur.nsa.short,s.window=15)
ur.nsa.short.sa <- seasadj(fit)
#let's see the results
plot(ur.nsa.short, col="gray", ylab = "Percent", main = "Adjusting unemployment")
fit <- stl(ur.nsa.short,s.window=15)
ur.nsa.short.sa <- seasadj(fit)
lines(ur.nsa.short.sa, col="red")
lines(ur.short, col = "blue")
legend("topright", legend=c("Unadjusted","R-adjusted","Published adj"), col=c("grey", "red", "blue"), lty = c(1,1,1))
require(quantmod)
require(ggplot2)
require(reshape2)
require(plyr)
require(scales)
#Tutorial:
#https://towardsdatascience.com/time-series-calendar-heatmaps-9f576578fcfe
# Download some Data, e.g. the CBOE VIX
#About VIX: https://en.wikipedia.org/wiki/VIX
getSymbols("FB",src="yahoo",auto.assign=TRUE)
# Make a dataframe
dat<-data.frame(date=index(FB),FB)
head(dat)
# We will facet by year ~ month, and each subgraph will
# show week-of-month versus weekday
# the year is simple
dat$year<-as.numeric(as.POSIXlt(dat$date)$year+1900)
# the month too
dat$month<-as.numeric(as.POSIXlt(dat$date)$mon+1)
# but turn months into ordered facors to control the appearance/ordering in the presentation
dat$monthf<-factor(dat$month,levels=as.character(1:12),labels=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"),ordered=TRUE)
# the day of week is again easily found
dat$weekday = as.POSIXlt(dat$date)$wday
# again turn into factors to control appearance/abbreviation and ordering
# I use the reverse function rev here to order the week top down in the graph
# you can cut it out to reverse week order
dat$weekdayf<-factor(dat$weekday,levels=rev(1:7),labels=rev(c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")),ordered=TRUE)
# the monthweek part is a bit trickier
# first a factor which cuts the data into month chunks
dat$yearmonth<-as.yearmon(dat$date)
dat$yearmonthf<-factor(dat$yearmonth)
# then find the "week of year" for each day
dat$week <- as.numeric(format(dat$date,"%W"))
# and now for each monthblock we normalize the week to start at 1
dat<-ddply(dat,.(yearmonthf),transform,monthweek=1+week-min(week))
# Now for the plot
P<- ggplot(dat, aes(monthweek, weekdayf, fill = FB.Close)) +
geom_tile(colour = "white") + facet_grid(year~monthf) + scale_fill_gradient(low="green", high="blue") +
labs(title = "Time-Series Calendar Heatmap") +  xlab("Week of Month") + ylab("")
P
library(tseries)
library(zoo)
#import dataset into a dataframe
cisco <- read.table('C:/Users/Xuan Pham/Dropbox/Fall_2019/BIA6315/code/Week 2/Data/cisco_00-10.csv', header=T, sep=',')
# create time series for cisco prices
ciscots <- zoo(cisco$Price, as.Date(as.character(cisco$Date), format = "%m/%d/%y"))
plot(ciscots)
hist(ciscots)
mean(ciscots)
plot(ciscots)
?rversion
ciscots <- zoo(cisco$Price, as.Date(as.character(cisco$Date), format = "%m/%d/%y"), order.by = index(cisco$Date))
ciscots <- zoo(cisco$Price, order.by = index(cisco$Date), as.Date(as.character(cisco$Date), format = "%m/%d/%y"))
library(tseries)
library(zoo)
#import dataset into a dataframe
cisco <- read.table('C:/Users/Xuan Pham/Dropbox/Fall_2019/BIA6315/code/Week 2/Data/cisco_00-10.csv', header=T, sep=',')
# create time series for cisco prices
ciscots <- zoo(cisco$Price, as.Date(as.character(cisco$Date), format = "%m/%d/%y"))
plot(ciscots)
hist(ciscots)
mean(ciscots)
