---
title: 'Week 8: Time Series Regression Analysis, Part 2'
author: "Xuan Pham"
date: "10/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## On Autocorrelation  

Last week, we examined time series regression models where the residuals are not correlated (i.e white noise). What happens if the residuals are correlated? 

```{r}
library(fpp2)
autoplot(uschange[,1:2], facets=TRUE) +
  xlab("Year") + ylab("") +
  ggtitle("Quarterly changes in US consumption
    and personal income")

cons_series <- uschange[,1:2]


ts.reg1 <- tslm(Consumption ~ Income, data= cons_series)
summary(ts.reg1)

checkresiduals(ts.reg1)
```

## Problems with Estimated Regression Model with Autocorrelated Errors  

1. Estimated regression coefficients are not the best estimates (i.e. biased estimates).  
2. Any statistical tests run on the model is incorrect. 
3. AICc is no longer a good guide for model selection/performance.  
4. p-values associated with coefficients are too small so predictor variables will appear to be important when they are not (i.e. spurious correlation/regression).  

# Dynamic Regression Models  

Dynamic regression models allows the error term to exhibit autocorrelation. We handle the autocorrelated error term by using ARIMA models.  

$$Y_t = {\beta_0} + {\beta_1}{x_{1,t}} + ... +{\beta_k}{x_{k,t}} + {\eta_t}$$
where 
$$ {\eta_t} \sim ARIMA(p,d,q)$$ 
For example, if ${\eta_t}$ follows an ARIMA(1,1,1) model, then the autocorrelated errors can be modeled as 

$${(1 - \phi_1B)}{(1-B)}{\eta_t}={(1+\theta_1B)}{\epsilon_t}$$

## Data Preparation  

In order to run a dynamic regression model, the target (dependent variable) and predictors (independent variables) need to be stationary. Thus, this leaves us with only an ARMA model to consider for the autocorrelated error term.  

If we rewrite the equations above, we get 

$${Y'_t}={\beta_1x'_{1,t}}+...+{\beta_kx'_{k,t}}+{\eta'_t}$$

$${(1 - \phi_1B)}{(1-B)}{\eta'_t}={(1+\theta_1B)}{\epsilon_t}$$

```{r}
ggAcf(ts.reg1$residuals)
ggPacf(ts.reg1$residuals)

residuals.fit1 <- Arima(ts.reg1$residuals, order=c(1,0,0))
residuals.fit2 <- Arima(ts.reg1$residuals, order=c(2,0,0))
residuals.fit3 <- Arima(ts.reg1$residuals, order=c(3,0,0))
residuals.fit4 <- Arima(ts.reg1$residuals, order=c(4,0,0))

residuals.fit1
residuals.fit2
residuals.fit3
residuals.fit4

fit.auto <- auto.arima(ts.reg1$residuals, approximation=FALSE, stepwise=FALSE)
fit.auto
```

```{r}
dynamic.reg.model1 <- Arima(cons_series[,1], xreg=cons_series[,2], order=c(3,0,0))

dynamic.reg.model1
```

Writing out the fitted model  

$$\hat{Consumption}_t = 0.601 + 0.197Income_t + \eta_t$$
$$\eta_t = 0.126\eta_{t-1} + 0.238\eta_{t-2} + 0.160\eta_{t-3} + \epsilon_t$$

$$\epsilon_{t} {\sim}N(0,0.321)$$

```{r}
cbind("Regression Errors" = residuals(dynamic.reg.model1, type="regression"),
      "ARIMA errors" = residuals(dynamic.reg.model1, type="innovation")) %>%
  autoplot(facets=TRUE)

checkresiduals(dynamic.reg.model1)
```

## Using auto.arima()

```{r}
dynamic.reg.auto <- auto.arima(uschange[,"Consumption"],
  xreg=uschange[,"Income"], approximation = FALSE, stepwise = FALSE)
dynamic.reg.auto
```
$$\hat{Consumption}_t = 0.601 + 0.184Income_t + \eta_t$$

$$\eta_t = (0.126\eta_{t-1} + 0.238\eta_{t-2} + 0.160\eta_{t-3}){(-0.012\eta_{t-1}-0.160\eta_{t-2})}_{4} + \epsilon_t$$
$$\epsilon_{t}{\sim}N(0,0.317)$$
#Forecasting  

When we forecast into the future, we need to obtain forecasts for the predictors. Sometimes, these predictor forecasts are known (such as whether an intervention was applied). Sometimes, these predictor forecasts are unknown. In these latter cases, we have to use our best judgments.  

We will calculate forecasts for the next eight quarters assuming that the future percentage changes in personal disposable income will be equal to the mean percentage change from the last forty years.

```{r}
mean.income.change <- mean(uschange[,2])
expected.income.change <- rep(mean.income.change,8)#repeats 8 times
fcast <- forecast(dynamic.reg.auto, xreg=expected.income.change, 8)
autoplot(fcast) + xlab("Year") +
  ylab("Percentage change")
```

# Daily Electricity Demand Example  

```{r}
autoplot(elecdaily[,c(1,3)], facets=TRUE) +
  xlab("Year") + ylab("") +
  ggtitle("Electricity Demand vs. Temperature by Half-Hour Increment in Victoria, Australia in 2014")

plot(elecdaily[,3], elecdaily[,1],
     main = "Electricy Demand vs. Temperature in Half Hour Increment", xlab = "Temperature", ylab = "Electricity Demand")
```

Can you fit a linear regression model where Demand is the target and WorkDay and Temperature are the predictors?  

```{r}
fit <- tslm(Demand~Temperature + WorkDay, data=elecdaily)
summary(fit)

Temperature_squared <- elecdaily[,3]^2
fit.quadratic <- tslm(Demand~Temperature + Temperature_squared + WorkDay, data=elecdaily)
summary(fit.quadratic)
```

Check the residuals and determine whether autocorrelation exists  

```{r}
checkresiduals(fit)
checkresiduals(fit.quadratic)
```

Fit a dynamic regression model if needed to account for autocorrelated residuals  

```{r}
predictors <- cbind(MaxTemp = elecdaily[, "Temperature"],
              MaxTempSq = elecdaily[, "Temperature"]^2,
              Workday = elecdaily[, "WorkDay"])
fit.auto <- auto.arima(elecdaily[,1], xreg=predictors,
                       approximation=FALSE, stepwise=FALSE)
fit.auto
```

Using the estimated model above, please forecast 14 days ahead starting from Thursday 1 January 2015 (a non-work-day being a public holiday for New Years Day). But for the sake of illustration, we will use scenario based forecasting where we set the temperature for the next 14 days to a constant 26 degrees. Revise the code chunk below to run your forecasts.  

```{r}
fcast <- forecast(fit.auto,
  xreg = cbind(MaxTemp=rep(26,14), MaxTempSq=rep(26^2,14),
    Workday=c(0,1,0,0,1,1,1,1,1,0,0,1,1,1)))
autoplot(fcast) + ylab("Electricity demand (GW)")
```


# Stochastic and Deterministic Trends  

When we have a linear trend in a dynamic regression model, we can model it in two ways: 

## 1. Deterministic  

$$Y_t = \beta_0 + \beta_{1}t + \eta_t$$
where $\eta_t$ follows an ARMA process.  

## 2. Stochastic  
$$Y_t = \beta_0 + \beta_{1}t + \eta_t$$ 
where $\eta_t$ follows an ARIMA process with d=1.  We can take the first-order difference so that the error term follows an ARMA process:

$$Y'_t = \beta_{1} + \eta'_t$$
$$Y_t = Y_{t-1} + \beta_{1} + \eta'_t$$ 
Even though they are similar, the forecasts for each type of trend are quite different.  

```{r}
autoplot(austa) + xlab("Year") +
  ylab("millions of people") +
  ggtitle("Total annual international visitors to Australia")
```

Deterministic trend  

```{r}
trend <- seq_along(austa)
fit1 <- auto.arima(austa, d=0, xreg=trend)
fit1
```

This model can be written as  
$$Y_t = 0.416 + 0.171t + \eta_t$$

$$\eta_t = 0.113\eta_{t-1} + 0.380\eta_{t-2} +\epsilon_t$$
$$\epsilon_{t} {\sim}N(0,0.030)$$



Stochastic trend  

```{r}
fit2 <- auto.arima(austa, d=1)
fit2
```

This model can be written as  
$$Y_t = Y_0 + 0.173t + \eta_t$$
$$\eta_t = \eta_{t-1} + 0.301\epsilon_{t-1} + \epsilon_t$$
$$\epsilon_{t} {\sim}N(0,0.034)$$
Although the point estimates are the same, the prediction intervals are not.  

```{r}
fc1 <- forecast(fit1,
  xreg = length(austa) + 1:10)
fc2 <- forecast(fit2, h=10)
autoplot(austa) +
  autolayer(fc2, series="Stochastic trend") +
  autolayer(fc1, series="Deterministic trend") +
  ggtitle("Forecasts from trend models") +
  xlab("Year") + ylab("Visitors to Australia (millions)") +
  guides(colour=guide_legend(title="Forecast"))
```

From Hyndman (2019, Section 9.4):  

There is an implicit assumption with deterministic trends that the slope of the trend is not going to change over time. On the other hand, stochastic trends can change, and the estimated growth is only assumed to be the average growth over the historical period, not necessarily the rate of growth that will be observed into the future. Consequently, it is safer to forecast with stochastic trends, especially for longer forecast horizons, as the prediction intervals allow for greater uncertainty in future growth (Hyndman 2019, https://otexts.com/fpp2/stochastic-and-deterministic-trends.html).

# Dynamic Harmonic Regression  

Remember we learned last week that the maximum number of sine and cosine terms to include in a harmonic regression is equivalent to 1/2 the number of periods in a season.  

```{r}
cafe04 <- window(auscafe, start=2004)

plot(cafe04, main = "Monthly Restaurant/Cafe Expenditures (in billions of dollars")
```
The variance seem to be changing. We should consider transforming the series to stabilize the variance.  

```{r}
plots <- list()
for (i in seq(6)) {
  fit <- auto.arima(cafe04, xreg = fourier(cafe04, K = i),
    seasonal = FALSE, lambda = 0)
  plots[[i]] <- autoplot(forecast(fit,
      xreg=fourier(cafe04, K=i, h=24))) +
    xlab(paste("K=",i,"   AICC=",round(fit[["aicc"]],2))) +
    ylab("") + ylim(1.5,4.7)
}
gridExtra::grid.arrange(
  plots[[1]],plots[[2]],plots[[3]],
  plots[[4]],plots[[5]],plots[[6]], nrow=3)

```

The model with the lowest AICc is the fifth dynamic harmonic regression model with five pairs of sine and cosine terms and errors with ARIMA(0,1,1). 

```{r}
fit <- auto.arima(cafe04, xreg = fourier(cafe04, K = 5),
    seasonal = FALSE, lambda = 0)

fit
```

# Lagged Predictors  

The impact of a predictor may be spread out over multiple periods.  

$$Y_t = \beta_0 + \gamma_0x_t + \gamma_1x_{t-1} + \gamma_2x_{t-2} + ... + \gamma_kx_{t-k} + \eta_t  $$
where $\eta_t$ follows an ARIMA process.  

```{r}
autoplot(insurance, facets=TRUE) +
  xlab("Year") + ylab("") +
  ggtitle("Insurance advertising and quotations")
```

```{r}
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(
    AdLag0 = insurance[,"TV.advert"],
    AdLag1 = stats::lag(insurance[,"TV.advert"],-1),
    AdLag2 = stats::lag(insurance[,"TV.advert"],-2),
    AdLag3 = stats::lag(insurance[,"TV.advert"],-3)) %>%
  head(NROW(insurance))

# Restrict data so models use same fitting period
# Starting with April 2002 through April 2005
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1],
  stationary=TRUE)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2],
  stationary=TRUE)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3],
  stationary=TRUE)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4],
  stationary=TRUE)

c(fit1[["aicc"]],fit2[["aicc"]],fit3[["aicc"]],fit4[["aicc"]])
```

Re-estimate the model with two lagged predictors. 

```{r}
(fit <- auto.arima(insurance[,1], xreg=Advert[,1:2],
  stationary=TRUE))
```

Forecast 8 periods into the future  

```{r}
fc8 <- forecast(fit, h=20,
  xreg=cbind(AdLag0 = rep(8,20),
             AdLag1 = c(Advert[40,1], rep(8,19))))
autoplot(fc8) + ylab("Quotes") +
  ggtitle("Forecast quotes with future advertising set to 8")
```